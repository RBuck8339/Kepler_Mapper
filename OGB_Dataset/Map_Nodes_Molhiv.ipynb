{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 40], edge_attr=[40, 3], x=[19, 9], y=[1, 1], num_nodes=19)\n",
      "41127\n",
      "Number of 1s: 1443\n",
      "Number of 0s: 39684\n",
      "KeplerMapper(verbose=2)\n",
      "..Composing projection pipeline of length 1:\n",
      "\tProjections: TSNE()\n",
      "\tDistance matrices: False\n",
      "\tScalers: None\n",
      "..Projecting on data shaped (1049163, 60)\n",
      "\n",
      "..Projecting data using: \n",
      "\tTSNE(verbose=2)\n",
      "\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1049163 samples in 0.070s...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Digits Dataset\n",
    "================\n",
    "\n",
    "This digits example shows two ways of customizing the tooltips options in the HTML visualization. It generates the visualization with tooltips set as the y-label, or number of the image. The second generated result uses the actual image in the tooltips.\n",
    "\n",
    "`Visualization with y-label tooltip <../../_static/digits_ylabel_tooltips.html>`_\n",
    "\n",
    "`Visualization with custom tooltips <../../_static/digits_custom_tooltips.html>`_\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "import io\n",
    "import sys\n",
    "import base64\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import kmapper as km\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torch\n",
    "# from rdkit.Chem.rdmolfiles import MolFromSmiles\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder  # Given at start\n",
    "from ogb.utils import features  # To get my features\n",
    "from ogb.utils import mol  # To make the SMILES into a tensor\n",
    "from ogb.utils import torch_util  # If needed, to create numpy to tensor\n",
    "from ogb.graphproppred import PygGraphPropPredDataset  # To get my dataset to work with\n",
    "\n",
    "from rdkit import Chem\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from helpers import createFolder\n",
    "from helpers import copyFile\n",
    "\n",
    "dir = 'C:/Users/ronan/OneDrive/Documents/GitHub/test/Kepler_Mapper/'\n",
    "html_template = dir + \"Outputs/Visualizations/digits_custom_tooltips.html\"\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Given at start\n",
    "atom_encoder = AtomEncoder(emb_dim=60)  # Class object for node embeddings\n",
    "# These automatically scale the data with an Xavier Uniform Distribution\n",
    "\n",
    "dataset = PygGraphPropPredDataset(name='ogbg-molhiv', root='/OGB_Dataset')  # Load the dataset\n",
    "print(dataset[0])\n",
    "print(len(dataset))\n",
    "# Generate labels for graph\n",
    "\n",
    "labels = pd.read_csv(dir + 'OGB_Dataset/ogbg_molhiv/mapping/mol.csv.gz', compression='gzip').iloc[:,\n",
    "         0]  # Get the graph labels\n",
    "labels = labels.to_list()\n",
    "\n",
    "total_ones = labels.count(1)\n",
    "total_zeros = labels.count(0)\n",
    "\n",
    "print(\"Number of 1s:\", total_ones)  # display number of ones in the dataset\n",
    "print(\"Number of 0s:\", total_zeros)  # display number of zeros in the dataset\n",
    "\n",
    "# Generate labels for visualization\n",
    "binary_labels = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    for label in range(dataset[i].num_nodes):\n",
    "        binary_labels.append(labels[label])\n",
    "\n",
    "tooltip_s = np.array(binary_labels)\n",
    "\n",
    "# Generate embeddings for all nodes in dataset\n",
    "tlist_atom_embeddings = []\n",
    "nplist_atom_embeddings = []\n",
    "for node in range(len(dataset)):\n",
    "    # Get the embeddings for current SMILES\n",
    "    atom_embedding = atom_encoder(dataset[node].x)  # Get the embedding of given SMILES equation\n",
    "    tlist_atom_embeddings.append(atom_embedding)  # Add tensor to our list of tensors\n",
    "\n",
    "for tensor in tlist_atom_embeddings:\n",
    "    for item in tensor:\n",
    "        nplist_atom_embeddings.append(item.detach().numpy())\n",
    "\n",
    "nplist_atom_embeddings = np.asarray(nplist_atom_embeddings)\n",
    "\n",
    "# Initialize the mapper object\n",
    "mapper = km.KeplerMapper(verbose=2)\n",
    "\n",
    "projected_data = mapper.fit_transform(nplist_atom_embeddings, projection=sklearn.manifold.TSNE(), scaler=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = dir + \"ForKiarash\"\n",
    "createFolder(folder_dir)\n",
    "copyFile(folder_dir, html_template)\n",
    "folder_dir = folder_dir + \"/\"\n",
    "\n",
    "graph = mapper.map(\n",
    "    projected_data,\n",
    "    clusterer=sklearn.cluster.KMeans(n_clusters=10, random_state=42, n_init=1),\n",
    "    # clusterer=grid_result,\n",
    "    cover=km.Cover(10, 0.6))\n",
    "# cover=km.Cover(n_cubes=5, perc_overlap=0.4))\n",
    "\n",
    "# Tooltips with image data for every cluster member\n",
    "mapper.visualize(\n",
    "    graph,\n",
    "    title=\"Handwritten digits Mapper\",\n",
    "    path_html=folder_dir + \"digits_custom_tooltips.html\",\n",
    "    color_values=binary_labels,\n",
    "    color_function_name=\"labels\",\n",
    "    custom_tooltips=tooltip_s,\n",
    ")\n",
    "\n",
    "num_members = []\n",
    "for key in graph[\"nodes\"]:\n",
    "    num_members.append(len(graph[\"nodes\"][key]))\n",
    "\n",
    "num_members_df = pd.DataFrame(num_members)\n",
    "num_members_df.index = graph[\"nodes\"].keys()\n",
    "num_members_df = num_members_df.transpose()\n",
    "num_members_df.to_csv(folder_dir + 'NumMembers.csv', index=False)\n",
    "\n",
    "print(\"Wrote dataframe containing number of members in each cluster to: Outputs/NumMembers.csv\")\n",
    "\n",
    "'''\n",
    "count_nodes_keys = graph[\"nodes\"].keys()\n",
    "members_df = pd.DataFrame(graph_memberships, columns=count_nodes_keys)\n",
    "members_df.to_csv()\n",
    "'''\n",
    "\n",
    "count_graph_nodes_dict = dict.fromkeys(graph[\"nodes\"].keys())\n",
    "\n",
    "list_sizes = [\"0-5 nodes\", \"6-15 nodes\", \"16-30 nodes\", \"31-60 nodes\", \"61-100 nodes\", \"101-250 nodes\", \"251-500 nodes\",\n",
    "              \"501-1000 nodes\", \"1001-2000 nodes\",\n",
    "              \"2001-4000 nodes\", \"4001-6000 nodes\", \"6001-10000 nodes\", \"10001-15000 nodes\", \"15001-20000 nodes\",\n",
    "              \"20001-30000 nodes\",\n",
    "              \"30001-45000 nodes\", \"45001-60000 nodes\", \"60001-80000 nodes\", \"80001-100000 nodes\",\n",
    "              \"100001-150000 nodes\", \"150001+ nodes\"]\n",
    "\n",
    "list_vals = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for key in list(graph[\"nodes\"].keys()):\n",
    "    if len(graph[\"nodes\"][key]) > 0 and len(graph[\"nodes\"][key]) <= 5:\n",
    "        list_vals[0] = list_vals[0] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 5 and len(graph[\"nodes\"][key]) <= 15:\n",
    "        list_vals[1] = list_vals[1] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 15 and len(graph[\"nodes\"][key]) <= 30:\n",
    "        list_vals[2] = list_vals[2] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 30 and len(graph[\"nodes\"][key]) <= 60:\n",
    "        list_vals[3] = list_vals[3] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 60 and len(graph[\"nodes\"][key]) <= 100:\n",
    "        list_vals[4] = list_vals[4] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 100 and len(graph[\"nodes\"][key]) <= 250:\n",
    "        list_vals[5] = list_vals[5] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 250 and len(graph[\"nodes\"][key]) <= 500:\n",
    "        list_vals[6] = list_vals[6] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 500 and len(graph[\"nodes\"][key]) <= 1000:\n",
    "        list_vals[7] = list_vals[7] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 1000 and len(graph[\"nodes\"][key]) <= 2000:\n",
    "        list_vals[8] = list_vals[8] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 2000 and len(graph[\"nodes\"][key]) <= 4000:\n",
    "        list_vals[9] = list_vals[9] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 4000 and len(graph[\"nodes\"][key]) <= 6000:\n",
    "        list_vals[10] = list_vals[10] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 6000 and len(graph[\"nodes\"][key]) <= 10000:\n",
    "        list_vals[11] = list_vals[11] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 10000 and len(graph[\"nodes\"][key]) <= 15000:\n",
    "        list_vals[12] = list_vals[12] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 15000 and len(graph[\"nodes\"][key]) <= 20000:\n",
    "        list_vals[13] = list_vals[13] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 20000 and len(graph[\"nodes\"][key]) <= 30000:\n",
    "        list_vals[14] = list_vals[14] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 30000 and len(graph[\"nodes\"][key]) <= 45000:\n",
    "        list_vals[15] = list_vals[15] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 45000 and len(graph[\"nodes\"][key]) <= 60000:\n",
    "        list_vals[16] = list_vals[16] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 60000 and len(graph[\"nodes\"][key]) <= 80000:\n",
    "        list_vals[17] = list_vals[17] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 80000 and len(graph[\"nodes\"][key]) <= 100000:\n",
    "        list_vals[18] = list_vals[18] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 100000 and len(graph[\"nodes\"][key]) <= 150000:\n",
    "        list_vals[19] = list_vals[19] + 1\n",
    "    elif len(graph[\"nodes\"][key]) > 150000:\n",
    "        list_vals[20] = list_vals[20] + 1\n",
    "\n",
    "count_node_sizes_dict = dict(zip(list_sizes, list_vals))\n",
    "\n",
    "index = [\"num_occurrances\"]\n",
    "count_graph_nodes_df = pd.DataFrame(count_node_sizes_dict, index=index)\n",
    "\n",
    "count_graph_nodes_df.to_csv(folder_dir + 'ClusterSizes.csv', index=False)\n",
    "\n",
    "print(\"Wrote dataframe containing cluster sizes to \" + folder_dir + \"ClusterSizes.csv\")\n",
    "\n",
    "list_sizes = [\"1-5 nodes\", \"6-9 nodes\", \"10-12 nodes\", \"13-14 nodes\", \"15 nodes\", \"16 nodes\", \"17 nodes\", \"18 nodes\",\n",
    "              \"19 nodes\", \"20 nodes\", \"21 nodes\", \"22 nodes\",\n",
    "              \"23 nodes\", \"24 nodes\", \"25 nodes\", \"26 nodes\", \"27 nodes\", \"28 nodes\", \"29 nodes\", \"30 nodes\",\n",
    "              \"31 nodes\", \"32 nodes\", \"33 nodes\", \"34 nodes\", \"35 nodes\",\n",
    "              \"36-38 nodes\", \"39-40 nodes\", \"41-43 nodes\", \"44-45 nodes\", \"46+ nodes\"]\n",
    "\n",
    "list_vals = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    if dataset[i].num_nodes > 0 and dataset[i].num_nodes <= 5:\n",
    "        list_vals[0] = list_vals[0] + 1\n",
    "    elif dataset[i].num_nodes > 5 and dataset[i].num_nodes <= 9:\n",
    "        list_vals[1] = list_vals[1] + 1\n",
    "    elif dataset[i].num_nodes > 9 and dataset[i].num_nodes <= 12:\n",
    "        list_vals[2] = list_vals[2] + 1\n",
    "    elif dataset[i].num_nodes > 12 and dataset[i].num_nodes <= 14:\n",
    "        list_vals[3] = list_vals[3] + 1\n",
    "    elif dataset[i].num_nodes == 15:\n",
    "        list_vals[4] = list_vals[4] + 1\n",
    "    elif dataset[i].num_nodes == 16:\n",
    "        list_vals[5] = list_vals[5] + 1\n",
    "    elif dataset[i].num_nodes == 17:\n",
    "        list_vals[6] = list_vals[6] + 1\n",
    "    elif dataset[i].num_nodes == 18:\n",
    "        list_vals[7] = list_vals[7] + 1\n",
    "    elif dataset[i].num_nodes == 19:\n",
    "        list_vals[8] = list_vals[8] + 1\n",
    "    elif dataset[i].num_nodes == 20:\n",
    "        list_vals[9] = list_vals[9] + 1\n",
    "    elif dataset[i].num_nodes == 21:\n",
    "        list_vals[10] = list_vals[10] + 1\n",
    "    elif dataset[i].num_nodes == 22:\n",
    "        list_vals[11] = list_vals[11] + 1\n",
    "    elif dataset[i].num_nodes == 23:\n",
    "        list_vals[12] = list_vals[12] + 1\n",
    "    elif dataset[i].num_nodes == 24:\n",
    "        list_vals[13] = list_vals[13] + 1\n",
    "    elif dataset[i].num_nodes == 25:\n",
    "        list_vals[14] = list_vals[14] + 1\n",
    "    elif dataset[i].num_nodes == 26:\n",
    "        list_vals[15] = list_vals[15] + 1\n",
    "    elif dataset[i].num_nodes == 27:\n",
    "        list_vals[16] = list_vals[16] + 1\n",
    "    elif dataset[i].num_nodes == 28:\n",
    "        list_vals[17] = list_vals[17] + 1\n",
    "    elif dataset[i].num_nodes == 29:\n",
    "        list_vals[18] = list_vals[18] + 1\n",
    "    elif dataset[i].num_nodes == 30:\n",
    "        list_vals[19] = list_vals[19] + 1\n",
    "    elif dataset[i].num_nodes == 31:\n",
    "        list_vals[20] = list_vals[20] + 1\n",
    "    elif dataset[i].num_nodes == 32:\n",
    "        list_vals[21] = list_vals[21] + 1\n",
    "    elif dataset[i].num_nodes == 33:\n",
    "        list_vals[22] = list_vals[22] + 1\n",
    "    elif dataset[i].num_nodes == 34:\n",
    "        list_vals[23] = list_vals[23] + 1\n",
    "    elif dataset[i].num_nodes == 35:\n",
    "        list_vals[24] = list_vals[24] + 1\n",
    "    elif dataset[i].num_nodes > 35 and dataset[i].num_nodes <= 38:\n",
    "        list_vals[25] = list_vals[25] + 1\n",
    "    elif dataset[i].num_nodes > 39 and dataset[i].num_nodes <= 40:\n",
    "        list_vals[27] = list_vals[26] + 1\n",
    "    elif dataset[i].num_nodes > 40 and dataset[i].num_nodes <= 43:\n",
    "        list_vals[28] = list_vals[27] + 1\n",
    "    elif dataset[i].num_nodes > 43 and dataset[i].num_nodes <= 45:\n",
    "        list_vals[29] = list_vals[28] + 1\n",
    "    elif dataset[i].num_nodes > 45:\n",
    "        list_vals[30] = list_vals[29] + 1\n",
    "\n",
    "count_node_sizes_dict = dict(zip(list_sizes, list_vals))\n",
    "\n",
    "index = [\"num_occurrances\"]\n",
    "count_graph_nodes_df = pd.DataFrame(count_node_sizes_dict, index=index)\n",
    "\n",
    "count_graph_nodes_df.to_csv(folder_dir + 'GraphSizes.csv', index=False)\n",
    "\n",
    "print(\"Wrote dataframe containing graph sizes to \" + folder_dir + \"GraphSizes.csv\")\n",
    "\n",
    "graph_copy = graph\n",
    "\n",
    "graph_indicators = []\n",
    "with open('OGB_Dataset\\Created_Files\\Graph_Indicator.txt', \"r\") as f:\n",
    "    for line in f:\n",
    "        graph_indicators.append(int(line))\n",
    "\n",
    "# Get all column names\n",
    "columns = [\"graph number\"]\n",
    "columns = columns + list(graph[\"nodes\"].keys())\n",
    "columns = columns + [\"Graph Label\"]\n",
    "\n",
    "# Modify the graph_copy to have graph indicators so we can count where the nodes appear\n",
    "for key, values in graph_copy[\"nodes\"].items():\n",
    "    for i in range(len(values)):\n",
    "        values[i] = graph_indicators[values[i] - 1]\n",
    "\n",
    "num_nodes_cluster_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for num in range(len(dataset)):\n",
    "    new_row = []\n",
    "    new_row.append(num)\n",
    "    for key in graph_copy[\"nodes\"].keys():\n",
    "        new_row.append((graph_copy[\"nodes\"][key]).count(num))\n",
    "    new_row.append(dataset[num].y)\n",
    "    num_nodes_cluster_df.loc[len(num_nodes_cluster_df)] = new_row\n",
    "\n",
    "num_nodes_cluster_df.to_csv(folder_dir + 'GraphNodeDistributions.csv', index=False)\n",
    "\n",
    "print(\"Wrote dataframe containing node distributions to \" + folder_dir + \"GraphNodeDistributions.csv\")\n",
    "\n",
    "\n",
    "new_graph = graph  # Reset graph_copy\n",
    "\n",
    "# Prints out all nodes in their clusters with their node labels, what I think I will want to do is, for each node in node,\n",
    "#  then give them their graph label from the txt file\n",
    "\n",
    "for key in (new_graph[\"nodes\"]):\n",
    "    for value in range(len(list(new_graph[\"nodes\"][key]))):\n",
    "        new_graph[\"nodes\"][key][value] = str(binary_labels[new_graph[\"nodes\"][key][value]])\n",
    "\n",
    "total_ones = 0\n",
    "total_zeros = 0\n",
    "\n",
    "for key in new_graph[\"nodes\"]:\n",
    "    total_ones += new_graph[\"nodes\"][key].count(\"1\")\n",
    "    total_zeros += new_graph[\"nodes\"][key].count(\"0\")\n",
    "\n",
    "list_nodes_info = []\n",
    "\n",
    "for key in new_graph[\"nodes\"]:\n",
    "    # print(key, \" size is: \", len(graph_copy[\"nodes\"][key]))\n",
    "    ones_in_cluster = new_graph[\"nodes\"][key].count(\"1\")\n",
    "    zeros_in_cluster = new_graph[\"nodes\"][key].count(\"0\")\n",
    "\n",
    "    ones_not_in_cluster = total_ones - ones_in_cluster\n",
    "    zeros_not_in_cluster = total_zeros - zeros_in_cluster\n",
    "\n",
    "    if (zeros_in_cluster != 0):\n",
    "        odds_ratio = (ones_in_cluster / zeros_in_cluster) / (ones_not_in_cluster / zeros_not_in_cluster)\n",
    "    else:\n",
    "        odds_ratio = 100\n",
    "\n",
    "    # print(\"Odds Ratio is: \", odds_ratio)\n",
    "\n",
    "    list_nodes_info.append((key, ones_in_cluster, zeros_in_cluster, odds_ratio))\n",
    "\n",
    "# Define column names (optional, but recommended)\n",
    "columns = [\"key\", \"number of ones\", \"number of zeros\", \"odds ratio\"]\n",
    "\n",
    "# Create DataFrame from list of tuples\n",
    "nodes_df = pd.DataFrame(list_nodes_info, columns=columns)\n",
    "nodes_df = nodes_df.sort_values(by='odds ratio', ascending=False)\n",
    "nodes_df.to_csv(folder_dir + 'OddsRatio.csv')\n",
    "\n",
    "print(\"Wrote Odds Ratios to: \" + folder_dir + \"OddsRatio.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]:\n",
    "    for j in [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]:\n",
    "        for k in [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "\n",
    "            folder_dir = dir + \"Outputs/ParamSearch/nclusters\" + str(i) + \"_ncubes\" + str(j) + \"_percoverlap\" + str(k)\n",
    "\n",
    "            createFolder(folder_dir)\n",
    "\n",
    "            folder_dir = folder_dir + \"/\"\n",
    "\n",
    "            createFolder(folder_dir + \"Visualizations\")\n",
    "            copyFile(folder_dir + \"Visualizations\", html_template)\n",
    "\n",
    "            graph = mapper.map(\n",
    "                projected_data,\n",
    "                clusterer=sklearn.cluster.KMeans(n_clusters=i, random_state=42, n_init=1),\n",
    "                # clusterer=grid_result,\n",
    "                cover=km.Cover(j, k))\n",
    "            # cover=km.Cover(n_cubes=5, perc_overlap=0.4))\n",
    "\n",
    "            # Tooltips with image data for every cluster member\n",
    "            mapper.visualize(\n",
    "                graph,\n",
    "                title=\"Handwritten digits Mapper\",\n",
    "                path_html=folder_dir + \"Visualizations/digits_custom_tooltips.html\",\n",
    "                color_values=binary_labels,\n",
    "                color_function_name=\"labels\",\n",
    "                custom_tooltips=tooltip_s,\n",
    "            )\n",
    "\n",
    "            num_members = []\n",
    "            for key in graph[\"nodes\"]:\n",
    "                num_members.append(len(graph[\"nodes\"][key]))\n",
    "\n",
    "            num_members_df = pd.DataFrame(num_members)\n",
    "            num_members_df.index = graph[\"nodes\"].keys()\n",
    "            num_members_df = num_members_df.transpose()\n",
    "            num_members_df.to_csv(folder_dir + 'NumMembers.csv', index=False)\n",
    "\n",
    "            print(\"Wrote dataframe containing number of members in each cluster to: \" + folder_dir + \"NumMembers.csv\")\n",
    "\n",
    "            '''\n",
    "            count_nodes_keys = graph[\"nodes\"].keys()\n",
    "            members_df = pd.DataFrame(graph_memberships, columns=count_nodes_keys)\n",
    "            members_df.to_csv()\n",
    "            '''\n",
    "\n",
    "            count_graph_nodes_dict = dict.fromkeys(graph[\"nodes\"].keys())\n",
    "\n",
    "            list_sizes = [\"0-5 nodes\", \"6-15 nodes\", \"16-30 nodes\", \"31-60 nodes\", \"61-100 nodes\", \"101-250 nodes\",\n",
    "                          \"251-500 nodes\", \"501-1000 nodes\", \"1001-2000 nodes\",\n",
    "                          \"2001-4000 nodes\", \"4001-6000 nodes\", \"6001-10000 nodes\", \"10001-15000 nodes\",\n",
    "                          \"15001-20000 nodes\", \"20001-30000 nodes\",\n",
    "                          \"30001-45000 nodes\", \"45001-60000 nodes\", \"60001-80000 nodes\", \"80001-100000 nodes\",\n",
    "                          \"100001-150000 nodes\", \"150001+ nodes\"]\n",
    "\n",
    "            list_vals = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "            for key in list(graph[\"nodes\"].keys()):\n",
    "                if len(graph[\"nodes\"][key]) > 0 and len(graph[\"nodes\"][key]) <= 5:\n",
    "                    list_vals[0] = list_vals[0] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 5 and len(graph[\"nodes\"][key]) <= 15:\n",
    "                    list_vals[1] = list_vals[1] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 15 and len(graph[\"nodes\"][key]) <= 30:\n",
    "                    list_vals[2] = list_vals[2] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 30 and len(graph[\"nodes\"][key]) <= 60:\n",
    "                    list_vals[3] = list_vals[3] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 60 and len(graph[\"nodes\"][key]) <= 100:\n",
    "                    list_vals[4] = list_vals[4] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 100 and len(graph[\"nodes\"][key]) <= 250:\n",
    "                    list_vals[5] = list_vals[5] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 250 and len(graph[\"nodes\"][key]) <= 500:\n",
    "                    list_vals[6] = list_vals[6] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 500 and len(graph[\"nodes\"][key]) <= 1000:\n",
    "                    list_vals[7] = list_vals[7] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 1000 and len(graph[\"nodes\"][key]) <= 2000:\n",
    "                    list_vals[8] = list_vals[8] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 2000 and len(graph[\"nodes\"][key]) <= 4000:\n",
    "                    list_vals[9] = list_vals[9] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 4000 and len(graph[\"nodes\"][key]) <= 6000:\n",
    "                    list_vals[10] = list_vals[10] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 6000 and len(graph[\"nodes\"][key]) <= 10000:\n",
    "                    list_vals[11] = list_vals[11] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 10000 and len(graph[\"nodes\"][key]) <= 15000:\n",
    "                    list_vals[12] = list_vals[12] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 15000 and len(graph[\"nodes\"][key]) <= 20000:\n",
    "                    list_vals[13] = list_vals[13] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 20000 and len(graph[\"nodes\"][key]) <= 30000:\n",
    "                    list_vals[14] = list_vals[14] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 30000 and len(graph[\"nodes\"][key]) <= 45000:\n",
    "                    list_vals[15] = list_vals[15] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 45000 and len(graph[\"nodes\"][key]) <= 60000:\n",
    "                    list_vals[16] = list_vals[16] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 60000 and len(graph[\"nodes\"][key]) <= 80000:\n",
    "                    list_vals[17] = list_vals[17] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 80000 and len(graph[\"nodes\"][key]) <= 100000:\n",
    "                    list_vals[18] = list_vals[18] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 100000 and len(graph[\"nodes\"][key]) <= 150000:\n",
    "                    list_vals[19] = list_vals[19] + 1\n",
    "                elif len(graph[\"nodes\"][key]) > 150000:\n",
    "                    list_vals[20] = list_vals[20] + 1\n",
    "\n",
    "            count_node_sizes_dict = dict(zip(list_sizes, list_vals))\n",
    "\n",
    "            index = [\"num_occurrances\"]\n",
    "            count_graph_nodes_df = pd.DataFrame(count_node_sizes_dict, index=index)\n",
    "\n",
    "            count_graph_nodes_df.to_csv(folder_dir + 'ClusterSizes.csv', index=False)\n",
    "\n",
    "            print(\"Wrote dataframe containing cluster sizes to \" + folder_dir + \"ClusterSizes.csv\")\n",
    "\n",
    "            list_sizes = [\"1-5 nodes\", \"6-9 nodes\", \"10-12 nodes\", \"13-14 nodes\", \"15 nodes\", \"16 nodes\", \"17 nodes\",\n",
    "                          \"18 nodes\", \"19 nodes\", \"20 nodes\", \"21 nodes\", \"22 nodes\",\n",
    "                          \"23 nodes\", \"24 nodes\", \"25 nodes\", \"26 nodes\", \"27 nodes\", \"28 nodes\", \"29 nodes\",\n",
    "                          \"30 nodes\", \"31 nodes\", \"32 nodes\", \"33 nodes\", \"34 nodes\", \"35 nodes\",\n",
    "                          \"36-38 nodes\", \"39-40 nodes\", \"41-43 nodes\", \"44-45 nodes\", \"46+ nodes\"]\n",
    "\n",
    "            list_vals = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "            for l in range(len(dataset)):\n",
    "                if dataset[l].num_nodes > 0 and dataset[l].num_nodes <= 5:\n",
    "                    list_vals[0] = list_vals[0] + 1\n",
    "                elif dataset[l].num_nodes > 5 and dataset[l].num_nodes <= 9:\n",
    "                    list_vals[1] = list_vals[1] + 1\n",
    "                elif dataset[l].num_nodes > 9 and dataset[l].num_nodes <= 12:\n",
    "                    list_vals[2] = list_vals[2] + 1\n",
    "                elif dataset[l].num_nodes > 12 and dataset[l].num_nodes <= 14:\n",
    "                    list_vals[3] = list_vals[3] + 1\n",
    "                elif dataset[l].num_nodes == 15:\n",
    "                    list_vals[4] = list_vals[4] + 1\n",
    "                elif dataset[l].num_nodes == 16:\n",
    "                    list_vals[5] = list_vals[5] + 1\n",
    "                elif dataset[l].num_nodes == 17:\n",
    "                    list_vals[6] = list_vals[6] + 1\n",
    "                elif dataset[l].num_nodes == 18:\n",
    "                    list_vals[7] = list_vals[7] + 1\n",
    "                elif dataset[l].num_nodes == 19:\n",
    "                    list_vals[8] = list_vals[8] + 1\n",
    "                elif dataset[l].num_nodes == 20:\n",
    "                    list_vals[9] = list_vals[9] + 1\n",
    "                elif dataset[l].num_nodes == 21:\n",
    "                    list_vals[10] = list_vals[10] + 1\n",
    "                elif dataset[l].num_nodes == 22:\n",
    "                    list_vals[11] = list_vals[11] + 1\n",
    "                elif dataset[l].num_nodes == 23:\n",
    "                    list_vals[12] = list_vals[12] + 1\n",
    "                elif dataset[l].num_nodes == 24:\n",
    "                    list_vals[13] = list_vals[13] + 1\n",
    "                elif dataset[l].num_nodes == 25:\n",
    "                    list_vals[14] = list_vals[14] + 1\n",
    "                elif dataset[l].num_nodes == 26:\n",
    "                    list_vals[15] = list_vals[15] + 1\n",
    "                elif dataset[l].num_nodes == 27:\n",
    "                    list_vals[16] = list_vals[16] + 1\n",
    "                elif dataset[i].num_nodes == 28:\n",
    "                    list_vals[17] = list_vals[17] + 1\n",
    "                elif dataset[l].num_nodes == 29:\n",
    "                    list_vals[18] = list_vals[18] + 1\n",
    "                elif dataset[l].num_nodes == 30:\n",
    "                    list_vals[19] = list_vals[19] + 1\n",
    "                elif dataset[l].num_nodes == 31:\n",
    "                    list_vals[20] = list_vals[20] + 1\n",
    "                elif dataset[l].num_nodes == 32:\n",
    "                    list_vals[21] = list_vals[21] + 1\n",
    "                elif dataset[l].num_nodes == 33:\n",
    "                    list_vals[22] = list_vals[22] + 1\n",
    "                elif dataset[l].num_nodes == 34:\n",
    "                    list_vals[23] = list_vals[23] + 1\n",
    "                elif dataset[l].num_nodes == 35:\n",
    "                    list_vals[24] = list_vals[24] + 1\n",
    "                elif dataset[l].num_nodes > 35 and dataset[l].num_nodes <= 38:\n",
    "                    list_vals[25] = list_vals[25] + 1\n",
    "                elif dataset[l].num_nodes > 39 and dataset[l].num_nodes <= 40:\n",
    "                    list_vals[27] = list_vals[26] + 1\n",
    "                elif dataset[l].num_nodes > 40 and dataset[l].num_nodes <= 43:\n",
    "                    list_vals[28] = list_vals[27] + 1\n",
    "                elif dataset[l].num_nodes > 43 and dataset[l].num_nodes <= 45:\n",
    "                    list_vals[29] = list_vals[28] + 1\n",
    "                elif dataset[l].num_nodes > 45:\n",
    "                    list_vals[30] = list_vals[29] + 1\n",
    "\n",
    "            count_node_sizes_dict = dict(zip(list_sizes, list_vals))\n",
    "\n",
    "            index = [\"num_occurrances\"]\n",
    "            count_graph_nodes_df = pd.DataFrame(count_node_sizes_dict, index=index)\n",
    "\n",
    "            count_graph_nodes_df.to_csv(folder_dir + 'GraphSizes.csv', index=False)\n",
    "\n",
    "            print(\"Wrote dataframe containing graph sizes to \" + folder_dir + \"GraphSizes.csv\")\n",
    "\n",
    "            graph_copy = graph\n",
    "\n",
    "            graph_indicators = []\n",
    "            with open('OGB_Dataset\\Created_Files\\Graph_Indicator.txt', \"r\") as f:\n",
    "                for line in f:\n",
    "                    graph_indicators.append(int(line))\n",
    "\n",
    "            # Get all column names\n",
    "            columns = [\"graph number\"]\n",
    "            columns = columns + list(graph[\"nodes\"].keys())\n",
    "            columns = columns + [\"Graph Label\"]\n",
    "\n",
    "            # Modify the graph_copy to have graph indicators so we can count where the nodes appear\n",
    "            for key, values in graph_copy[\"nodes\"].items():\n",
    "                for i in range(len(values)):\n",
    "                    values[i] = graph_indicators[values[i] - 1]\n",
    "\n",
    "            num_nodes_cluster_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "            for num in range(len(dataset)):\n",
    "                new_row = []\n",
    "                new_row.append(num)\n",
    "                for key in graph_copy[\"nodes\"].keys():\n",
    "                    new_row.append((graph_copy[\"nodes\"][key]).count(num))\n",
    "                new_row.append(dataset[num].y)\n",
    "                num_nodes_cluster_df.loc[len(num_nodes_cluster_df)] = new_row\n",
    "\n",
    "            num_nodes_cluster_df.to_csv(folder_dir + 'GraphNodeDistributions.csv', index=False)\n",
    "\n",
    "            print(\"Worte dataframe containing node distributions to \" + folder_dir + \"GraphNodeDistributions.csv\")\n",
    "\n",
    "            new_graph = graph  # Reset graph_copy\n",
    "\n",
    "            # Prints out all nodes in their clusters with their node labels, what I think I will want to do is, for each node in node,\n",
    "            #  then give them their graph label from the txt file\n",
    "\n",
    "            for key in (new_graph[\"nodes\"]):\n",
    "                for value in range(len(list(new_graph[\"nodes\"][key]))):\n",
    "                    new_graph[\"nodes\"][key][value] = str(binary_labels[new_graph[\"nodes\"][key][value]])\n",
    "\n",
    "            total_ones = 0\n",
    "            total_zeros = 0\n",
    "\n",
    "            for key in new_graph[\"nodes\"]:\n",
    "                total_ones += new_graph[\"nodes\"][key].count(\"1\")\n",
    "                total_zeros += new_graph[\"nodes\"][key].count(\"0\")\n",
    "\n",
    "            list_nodes_info = []\n",
    "\n",
    "            for key in new_graph[\"nodes\"]:\n",
    "                # print(key, \" size is: \", len(graph_copy[\"nodes\"][key]))\n",
    "                ones_in_cluster = new_graph[\"nodes\"][key].count(\"1\")\n",
    "                zeros_in_cluster = new_graph[\"nodes\"][key].count(\"0\")\n",
    "\n",
    "                ones_not_in_cluster = total_ones - ones_in_cluster\n",
    "                zeros_not_in_cluster = total_zeros - zeros_in_cluster\n",
    "\n",
    "                if (zeros_in_cluster != 0):\n",
    "                    odds_ratio = (ones_in_cluster / zeros_in_cluster) / (ones_not_in_cluster / zeros_not_in_cluster)\n",
    "                else:\n",
    "                    odds_ratio = 100\n",
    "\n",
    "                # print(\"Odds Ratio is: \", odds_ratio)\n",
    "\n",
    "                list_nodes_info.append((key, ones_in_cluster, zeros_in_cluster, odds_ratio))\n",
    "\n",
    "            # Define column names (optional, but recommended)\n",
    "            columns = [\"key\", \"number of ones\", \"number of zeros\", \"odds ratio\"]\n",
    "\n",
    "            # Create DataFrame from list of tuples\n",
    "            nodes_df = pd.DataFrame(list_nodes_info, columns=columns)\n",
    "            nodes_df = nodes_df.sort_values(by='odds ratio', ascending=False)\n",
    "            nodes_df.to_csv(folder_dir + 'OddsRatio.csv')\n",
    "\n",
    "            print(\"Wrote Odds Ratios to: \" + folder_dir + \"OddsRatio.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
